{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8532b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#opens file\n",
    "file = open(\"sampleLOB.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b668f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores data from file in array and strips whitespace\n",
    "data = [line for line in file.readlines() if re.search(\"[\\w].*\", line) != None][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3dda95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "organisedData = []\n",
    "#converts to human readable lines\n",
    "for line in data:\n",
    "    for word in line.split(\" \"):\n",
    "        if word != '\\x00':\n",
    "            charArray = word.split(\"\\x00\")[:-1]\n",
    "            modifiedWord = \"\"\n",
    "            for char in charArray:\n",
    "                modifiedWord += char\n",
    "                \n",
    "            #removes speech marks and commas of time, bid and ask lines\n",
    "            if \"time\" in modifiedWord or \"bid\" in modifiedWord or \"ask\" in modifiedWord:\n",
    "                modifiedWord = modifiedWord[1:-2]\n",
    "            organisedData.append(modifiedWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d5ca0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkArrayByWord(ls,chunkWord):   \n",
    "    chunkedData = []\n",
    "    chunk = []\n",
    "    for line in ls:\n",
    "        if line==chunkWord:\n",
    "            chunkedData.append(chunk)\n",
    "            chunk = []\n",
    "        else:\n",
    "            chunk.append(line)\n",
    "    return chunkedData\n",
    "\n",
    "chunkedData = chunkArrayByWord(organisedData, 'time')[1:]\n",
    "\n",
    "#remove entries where there are no entries in the order log book\n",
    "chunkedData = list(filter(lambda timeEntry: len(timeEntry)>3, chunkedData))\n",
    "\n",
    "evenChunkierData = []\n",
    "for time in chunkedData:\n",
    "    bidPos = 1 #it will always be 1\n",
    "    askPos = time.index('ask')\n",
    "    evenChunkierData.append([time[0], time[bidPos+1:askPos], time[askPos+1:]])\n",
    "\n",
    "organisedData = []\n",
    "for time in evenChunkierData:\n",
    "    bids = []\n",
    "    asks = []\n",
    "    for i, bid in enumerate(time[1]):\n",
    "        if i % 2 != 0:\n",
    "            bids.append(time[1][i-1:i+1]) #reconsider\n",
    "    for i, ask in enumerate(time[2]):\n",
    "        if i % 2 != 0:\n",
    "            asks.append(time[2][i-1:i+1]) #reconsider\n",
    "    organisedData.append([time[0], bids, asks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "651f6db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '3', '3', ..., '4', '2', '5'], dtype='<U32')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we aim to flatten the data into tabular data which we will eventually use for the csv file\n",
    "tabularData =[]\n",
    "for time in organisedData:\n",
    "    for bids in time[1]:\n",
    "        tabularData.append([\n",
    "            float(time[0][:-1]), #removes comma and converts to float\n",
    "            'bid',\n",
    "            int(bids[0][:-1]), #removes comma and converts to int\n",
    "            int(bids[1]) #converts to int\n",
    "        ])\n",
    "    for asks in time[2]:\n",
    "        tabularData.append([\n",
    "            float(time[0][:-1]), #removes comma and converts to float\n",
    "            'ask',\n",
    "            int(asks[0][:-1]),#removes comma and converts to int\n",
    "            int(asks[1]) #converts to int\n",
    "        ])       \n",
    "np.array(tabularData)[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "170a84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the time being I am going to save this as csv data\n",
    "dict = {\n",
    "    'Time': np.array(tabularData)[:,0],\n",
    "    'Transaction': np.array(tabularData)[:,1],\n",
    "    'Value': np.array(tabularData)[:,2],\n",
    "    'Amount': np.array(tabularData)[:,3],\n",
    "}  \n",
    "       \n",
    "df = pd.DataFrame(dict)\n",
    "df.to_csv('tabularData.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e7a8a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.496, 2.576, 'bid', 27, 3]]\n",
      "[[0.528, 'bid', 27, 3], [0.592, 'bid', 27, 3], [0.656, 'bid', 27, 3], [0.72, 'bid', 27, 3], [0.784, 'bid', 27, 3], [0.848, 'bid', 27, 3], [0.912, 'bid', 27, 3], [0.976, 'bid', 27, 3], [1.04, 'bid', 27, 3], [1.104, 'bid', 27, 3], [1.168, 'bid', 27, 3], [1.232, 'bid', 27, 3], [1.296, 'bid', 27, 3], [1.36, 'bid', 27, 3], [1.424, 'bid', 27, 3], [1.488, 'bid', 27, 3], [1.52, 'bid', 27, 3], [1.552, 'bid', 27, 3], [1.584, 'bid', 27, 3], [1.616, 'bid', 27, 3], [1.648, 'bid', 27, 3], [1.68, 'bid', 27, 3], [1.728, 'bid', 27, 3], [1.792, 'bid', 27, 3], [1.856, 'bid', 27, 3], [2.112, 'bid', 27, 3], [2.16, 'bid', 27, 3], [2.176, 'bid', 27, 3], [2.192, 'bid', 27, 3], [2.224, 'bid', 27, 3], [2.256, 'bid', 27, 3], [2.304, 'bid', 27, 3], [2.32, 'bid', 27, 3], [2.368, 'bid', 27, 3], [2.384, 'bid', 27, 3], [2.544, 'bid', 27, 3], [2.56, 'bid', 27, 3]]\n"
     ]
    }
   ],
   "source": [
    "#we now need to the start and end time of a bid or ask -> STILL BEING WORKED ON\n",
    "def createEntryWithStartAndEndTime(tabularData):\n",
    "    entryOfInterest = tabularData[0]\n",
    "    indexesOfIntrest = []\n",
    "    startDate = tabularData[0][0]\n",
    "    endDate = -1\n",
    "    for i, entry in enumerate(tabularData):\n",
    "        if entryOfInterest[-3:] == entry[-3:]:\n",
    "            indexesOfIntrest.append(i)\n",
    "            endDate = tabularData[indexesOfIntrest[-1]][0]\n",
    "    \n",
    "    for i in indexesOfIntrest: #need to check that there are not gaps in the indexes\n",
    "        tabularData.pop(i)\n",
    "    \n",
    "    return [([startDate, endDate] + entryOfInterest[1:])], tabularData\n",
    "\n",
    "entry, data = createEntryWithStartAndEndTime(tabularData)\n",
    "print(entry)\n",
    "print(list(filter(lambda e: e[-3:] == ['bid', 27, 3], data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "453d3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#ADITYA'S WORK DO NOT TOUCH\n",
    "rep = {\" \":\"\", \"\\\"\":\"\", \",\":\"\"}\n",
    "\n",
    "rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "\n",
    "str = \"\"\n",
    "list1 = []\n",
    "list2=[]\n",
    "\n",
    "matches = [\"[\", \"]\",\"\\n\",\"\\t\"]\n",
    "\n",
    "\n",
    "count = 0\n",
    "for f in file:\n",
    "    count +=1\n",
    "    line = f.strip()\n",
    "    f_line = pattern.sub(lambda m: rep[re.escape(m.group(0))], line)\n",
    "    if any(x in f_line for x in matches):\n",
    "        continue\n",
    "    else:\n",
    "#         str+=f_line\n",
    "#         print (str)\n",
    "        list1.append(f_line)\n",
    "\n",
    "list1 = list(filter(lambda a: a != {\" \"}, list1))\n",
    "print(count)\n",
    "\n",
    "for i in list1:\n",
    "    print(i)\n",
    "    \n",
    "# print(str)\n",
    "# list1 = str.split(\" \")\n",
    "# print(list1[0])\n",
    "# for i in str:\n",
    "#     if(i!=None and i!=\" \" and i!=\"\\n\" and i!=\"\\t\"):\n",
    "#         list2.append(i)\n",
    "# print(len(list1))\n",
    "# print(list1[0])\n",
    "# print(list2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957400f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590fe50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÿþ[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000t\u0000i\u0000m\u0000e\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u00000\u0000.\u00000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000b\u0000i\u0000d\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000[\u0000]\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000]\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000a\u0000s\u0000k\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000[\u0000]\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000]\u0000\n",
      "\u0000\n",
      "\u0000]\u0000\n",
      "\u0000\n",
      "\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000t\u0000i\u0000m\u0000e\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u00000\u0000.\u00000\u00001\u00006\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000b\u0000i\u0000d\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000[\u0000]\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000]\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000a\u0000s\u0000k\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000[\u0000]\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000]\u0000\n",
      "\u0000\n",
      "\u0000]\u0000\n",
      "\u0000\n",
      "\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000t\u0000i\u0000m\u0000e\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u00000\u0000.\u00000\u00003\u00002\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000b\u0000i\u0000d\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000[\u0000]\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000]\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000a\u0000s\u0000k\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000[\u0000]\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000]\u0000\n",
      "\u0000\n",
      "\u0000]\u0000\n",
      "\u0000\n",
      "\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000t\u0000i\u0000m\u0000e\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u00000\u0000.\u00000\u00004\u00008\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000b\u0000i\u0000d\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000[\u0000]\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000]\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000a\u0000s\u0000k\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000[\u0000]\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000]\u0000\n",
      "\u0000\n",
      "\u0000]\u0000\n",
      "\u0000\n",
      "\u0000[\u0000\n",
      "\u0000\n",
      "\u0000\u0000\u0000\u0000\u0000\u0000t\u0000i\u0000m\u0000e\u0000\u0000\u0000\n",
      "\u0000\n",
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "#ADITYA'S WORK DO NOT TOUCH\n",
    "with open('sampleLOB_50.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        current_line = pattern.sub(lambda m: rep[re.escape(m.group(0))], lines[i].strip())\n",
    "        print(current_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b068be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
